version: '2.3'

services:
  base_env:
    build:
      context: .
      dockerfile: ./Dockerfile
    image: toyrl_torch_base_image
    container_name: toyrl_torch_base_env

  gpu_env_windows:
    extends:
      service: base_env
    image: toyrl_torch_gpu_image
    container_name: toyrl_torch_gpu_env
    deploy:
      resources:
        reservations:
          devices:
            - capabilities:
              - gpu

#  gpu_env_linux:
#    extends:
#      service: base_env
#    runtime: nvidia

  jupyter:
    extends:
      service: gpu_env_windows
      #service: gpu_env_linux
    image: toyrl_torch_jupyter_image
    container_name: toyrl_torch_jupyter
    environment:
      PYTHONPATH: /src
      VERSION: "0.1"
    volumes:
      - ${input_dir:-./temp/inputs}:/workspace/inputs/:ro
      - ${output_dir:-./temp/outputs/}:/workspace/outputs/
      - ./temp:/workspace/temp
      - ./src/:/src:ro
      - ${local_config_path:-./configs}:/workspace/configs:ro
    working_dir: "/workspace"
    entrypoint: "bash -c 'jupyter lab --no-browser --ip=0.0.0.0 --port=${notebook_port:-18888} --allow-root --NotebookApp.password=${notebook_pw}'"
    #entrypoint: "python -c 'import torch; print(torch.cuda.is_available())'"
    ports:
      - "${notebook_ip:-0.0.0.0}:${notebook_port:-18888}:${notebook_port:-18888}"
    deploy:
      resources:
        reservations:
          devices:
            - capabilities:
              - gpu